---
title: 'AI Alignment'
description: 'Pioneering AI benchmarks for open source sustainability, governance, and human values'
date: 2025-11-16
---

## What is AI Alignment?

AI alignment is the effort to design Artificial Intelligence systems so their goals, behaviors, and decisions are consistent with human values and intentions, making them safe, helpful, and reliable.

## OSS Wishlist & AI Alignment

A potential of Open Source Wishlist is to pioneer how benchmarks are created for AI around sustainability topics like governance. By connecting maintainers with practitioners and capturing real-world needs, applying rubrics for success,  how might we buil a foundation for open source sustainability AI alignment?

## Get Involved

Join the conversation with the **CHAOSS AI Alignment Working Group** to help shape how AI systems understand and support open source health metrics.

<div class="mt-8">
  <a href="https://chaoss-workspace.slack.com/archives/C09GR3W4K4J" target="_blank" rel="noopener noreferrer" class="btn-primary inline-flex items-center gap-2">
    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z" />
    </svg>
    Join CHAOSS AI Alignment Working Group
  </a>
</div>


